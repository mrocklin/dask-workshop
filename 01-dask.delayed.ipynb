{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelize existing code with Dask.delayed\n",
    "\n",
    "In this section we parallelize simple for-loop style code with Dask and Dask.delayed.\n",
    "\n",
    "This is a simple way to use Dask to parallelize existing codebases or build complex systems.  This will also help us to build intuition for future sections.\n",
    "\n",
    "### Alternative software\n",
    "\n",
    "The solutions presented in this section are similar to the following tools:\n",
    "\n",
    "1.  concurrent.futures\n",
    "2.  multiprocessing.Pool\n",
    "3.  Airflow/Luigi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplest possible example\n",
    "\n",
    "We make some simple functions, inc and add, that sleep for a while to simulate work.  We time running these functions normally.  \n",
    "\n",
    "In the next section we'll parallelize this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def inc(x):\n",
    "    sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This takes three seconds to run because we call each function sequentially, one after the other\n",
    "%%time\n",
    "x = inc(1)\n",
    "y = inc(2)\n",
    "z = add(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelize with dask.delayed decorator\n",
    "\n",
    "Those two increment calls *could* be called in parallel.\n",
    "\n",
    "In this section we call `inc` and `add`, wrapped with `dask.delayed`.  This changes those functions so that they don't run immediately, but instead put those functions and arguments into a task graph.  Now when we run our code this runs immediately, but all it does it create a graph.  We then separately compute the result by calling the `.compute()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This runs immediately, all it does is build a graph\n",
    "%%time\n",
    "x = dask.delayed(inc)(1)\n",
    "y = dask.delayed(inc)(2)\n",
    "z = dask.delayed(add)(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This actually runs our computation using a local thread pool\n",
    "%%time\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "The `z` object is a lazy `dask.Delayed` object.  This object holds everything we need to compute the final result.  We can compute the result with `.compute()` as above or we can visualize the result with `.visualize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some questions to consider:\n",
    "\n",
    "-  Why did we go from 3s to 2s?  Why weren't we able to parallelize down to 1s?\n",
    "-  What would have happened if the inc and add functions didn't include the `sleep(1)`?  Would Dask still be able to speed up this code?\n",
    "-  What if we have multiple outputs or also want to get access to x or y?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelizing for-loop code with control flow\n",
    "\n",
    "Now we look at a more complex problem where we want to delay some parts of the computation, but not others.  Deciding what to delay is the hard part of using dask.delayed.\n",
    "\n",
    "We don't always want to wrap everything with `dask.delayed`.  In most cases we will mix immediate execution with delayed execution.  Generally we choose to immediately run (not delay) any code that decides what our computation will be (control flow), especially if it is fast, while we choose to delay functions that don't affect the shape of our computation, but do take a while to run.\n",
    "\n",
    "In the example below we iterate through a list of inputs and, based on whether the input is even or odd we choose to run either `inc` or `double`.  We collect these results into a list and sum them together.  \n",
    "\n",
    "-   Which parts of this computation decide what other computations we're going to run?  \n",
    "    We should not wrap these in dask.delayed because we need to know the answer immediately.\n",
    "-   Which parts of this computation can we delay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def double(x):\n",
    "    sleep(1)\n",
    "    return 2 * x\n",
    "\n",
    "def iseven(x):\n",
    "    return x % 2 == 0\n",
    "\n",
    "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "for x in data:\n",
    "    if iseven(x):\n",
    "        y = double(x)\n",
    "    else:\n",
    "        y = inc(x)\n",
    "    results.append(y)\n",
    "    \n",
    "total = sum(results)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "for x in data:\n",
    "    if iseven(x):  # even\n",
    "        y = dask.delayed(double)(x)\n",
    "    else:          # odd\n",
    "        y = dask.delayed(inc)(x)\n",
    "\n",
    "    results.append(y)\n",
    "    \n",
    "total = dask.delayed(sum)(results)\n",
    "total.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some questions to consider:\n",
    "\n",
    "-  What are other examples of control flow where we can't use delayed?\n",
    "-  What would have happened if we had delayed the evaluation of `iseven(x)` in the example above?\n",
    "-  What are your thoughts on delaying `sum`?  This function was both computational but also very fast to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas exercise\n",
    "\n",
    "In this exercise we read several CSV files and perform a groupby operation in parallel.  We are given sequential code to do this and parallelize it with Dask.delayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Prep data\n",
    "\n",
    "First, run this code to prep some data.  You don't need to understand this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from datetime import date, timedelta\n",
    "import dask.multiprocessing\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dirname = os.path.join('data', 'stocks')\n",
    "if os.path.exists(dirname):\n",
    "    shutil.rmtree(dirname)\n",
    "\n",
    "os.mkdir(dirname)\n",
    "\n",
    "def name_function(i):\n",
    "    return str(date(2015, 1, 1) + timedelta(days=1) * i)\n",
    "\n",
    "for symbol in ['GOOG', 'YHOO', 'AAPL', 'MSFT']:\n",
    "    df = dd.demo.daily_stock(symbol, '2015', '2016', freq='1s')\n",
    "    dirname = os.path.join('data', 'stocks', symbol)\n",
    "    os.mkdir(dirname)\n",
    "    df.to_csv(os.path.join('data', 'stocks', symbol, '*.csv'), \n",
    "              name_function=name_function, \n",
    "              get=dask.multiprocessing.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.listdir(os.path.join('data', 'stocks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.listdir(os.path.join('data', 'stocks', 'GOOG'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read one file with pandas.read_csv and compute spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(os.path.join('data', 'stocks', 'GOOG', '2015-01-01.csv'), \n",
    "                 parse_dates=['timestamp'], \n",
    "                 index_col='timestamp')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spread = df.high.max() - df.low.min()\n",
    "spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spread over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from glob import glob\n",
    "filenames = sorted(glob(os.path.join('data', 'stocks', 'GOOG', '*.csv')))\n",
    "\n",
    "spreads = []\n",
    "days = []\n",
    "for fn in filenames:\n",
    "    df = pd.read_csv(fn, parse_dates=['timestamp'], index_col='timestamp')\n",
    "    spread = df.high.max() - df.low.min()\n",
    "    day = df.index[0].date()\n",
    "    \n",
    "    spreads.append(spread)\n",
    "    days.append(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(days, spreads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: parallelize the code above\n",
    "\n",
    "Use dask.delayed to parallelize the code above.  Some extra things you will need to know.\n",
    "\n",
    "1.  Methods and attribute access on delayed objects work automatically, so if you have a delayed object you can perform normal arithmetic, slicing, and method calls on it and it will produce the correct delayed calls.\n",
    "\n",
    "    ```python\n",
    "    x = delayed(np.arange)(10)\n",
    "    y = (x + 1)[::2].sum()  # everything here was delayed\n",
    "    ```\n",
    "2.  Calling the `.compute()` method works well when you have a single output.  When you have multiple outputs you might want to use the `dask.compute` function:\n",
    "\n",
    "    ```python\n",
    "    >>> x = dask.delayed(np.arange)(10)\n",
    "    >>> y = x ** 2\n",
    "    >>> min, max = dask.compute(y.min(), y.max())\n",
    "    (0, 81)\n",
    "    ```\n",
    "    \n",
    "    This way dask can share the intermediate values (like `y = x**2`)\n",
    "    \n",
    "So your goal is to parallelize the code above (which has been copied below) using Dask.delayed.  You may also want to visualize a bit of the computation to see if you're doing it correctly.\n",
    "\n",
    "*Note: performance will improve a little bit, but not a whole lot.  We'll discuss why afterwards*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from glob import glob\n",
    "filenames = sorted(glob(os.path.join('data', 'stocks', 'GOOG', '*.csv')))\n",
    "\n",
    "spreads = []\n",
    "days = []\n",
    "for fn in filenames:\n",
    "    df = dask.delayed(pd.read_csv)(fn, parse_dates=['timestamp'], index_col='timestamp')\n",
    "    spread = df.high.max() - df.low.min()\n",
    "    day = df.index[0].date()\n",
    "    \n",
    "    spreads.append(spread)\n",
    "    days.append(day)\n",
    "    \n",
    "spreads, days = dask.compute(spreads, days)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
