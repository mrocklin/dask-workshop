{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Distributed\n",
    "\n",
    "In the previous notebook we used Dask.delayed to create computations.  By default, these ran on a local thread pool.  Often, this is sufficient, especially when you are bound by NumPy and Pandas routines which release the GIL and when you are using powerful workstation computers with many cores.\n",
    "\n",
    "However sometimes you may want to execute your code in processes (for Pure Python code that holds onto the GIL), in a single thread (for profiling and debugging) or across a cluster (for larger computations).\n",
    "\n",
    "In this section we will first talk about changing schedulers.  Then we'll use the dask.distributed scheduler in more depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous exercise\n",
    "\n",
    "One solution to the previous exercise follows below.  We run this same computation using three single-machine schedulers:\n",
    "\n",
    "1.  dask.threaded.get\n",
    "2.  dask.multiprocessing.get\n",
    "3.  dask.async.get_sync\n",
    "\n",
    "In each case we change the scheudler by providing a `get=` keyword argument like the following:\n",
    "\n",
    "```python\n",
    "total.compute(get=dask.multiprocessing.get)\n",
    "# or \n",
    "dask.compute(a, b, get=dask.multiprocessing.get)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask \n",
    "import dask.multiprocessing\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filenames = sorted(glob(os.path.join('data', 'stocks', 'GOOG', '*.csv')))\n",
    "\n",
    "spreads = []\n",
    "days = []\n",
    "for fn in filenames:\n",
    "    df = dask.delayed(pd.read_csv)(fn, parse_dates=['timestamp'], index_col='timestamp')\n",
    "    spread = df.high.max() - df.low.min()\n",
    "    day = df.index[0].date()\n",
    "    \n",
    "    spreads.append(spread)\n",
    "    days.append(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time s, d = dask.compute(spreads, days)  # this uses threads by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time s, d = dask.compute(spreads, days, get=dask.multiprocessing.get)  # this uses processes by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time s, d = dask.compute(spreads, days, get=dask.async.get_sync)  # This uses a single thread by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:  In what cases would you want to use one scheduler over another?\n",
    "\n",
    "http://dask.pydata.org/en/latest/scheduler-choice.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Scheduler\n",
    "\n",
    "The dask.distributed system is composed of a single centralizd scheduler and several worker processes.  We can follow the instructions here to set up dask.distributed on our local computer:\n",
    "\n",
    "http://distributed.readthedocs.io/en/latest/quickstart.html\n",
    "\n",
    "Either set up a dask-scheduler and dask-worker processes on your computer using the command line, or create a bare client below, which sets up a small cluster for you.  We recommend trying to use `dask-scheduler` and `dask-worker` directly first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# client = Client('localhost:8786')  # if you succeeded in setting up a dask-scheduler and dask-workers\n",
    "# client = Client()  # if you just want to have Dask set things up for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics\n",
    "\n",
    "One of the main advantages of using the distributed scheduler is the diagnostics dashboards that should be hosted live at http://localhost:8787/status .  Visit that link and then run the computation again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time s, d = dask.compute(spreads, days, get=client.get)  # This uses our \"distributed\" cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client takes over by default\n",
    "\n",
    "Actually, we didn't need to add `get=client.get`.  The distributed scheduler takes over as the default scheduler by default when the Client is instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time s, d = dask.compute(spreads, days)  # This used to use threads by default, now it uses dask.distributed"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
